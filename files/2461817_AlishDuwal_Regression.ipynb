{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Portfolio Project - Regression Task\n",
    "## CO2 Emissions Prediction Based on Vehicle Features\n",
    "\n",
    "**Student Name:** Alish Duwal  \n",
    "**Student ID:** 2461817  \n",
    "**Group:** L5CG2  \n",
    "\n",
    "**UN Sustainable Development Goal:** SDG 13 - Climate Action  \n",
    "**Objective:** Predict CO2 emissions (g/km) based on vehicle engine parameters and fuel consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Classical ML Models for Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Neural Network for Regression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel('/content/drive/MyDrive/FinalAssessment/CanadaCarEmissions.xlsx')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Information\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names\n",
    "print(\"Column Names:\")\n",
    "print(\"=\"*50)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(\"=\"*50)\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing CO2 emissions (target variable)\n",
    "print(\"Cleaning data...\")\n",
    "print(f\"Original dataset size: {len(df)}\")\n",
    "\n",
    "df_clean = df.dropna(subset=['CO2 EMISSIONS (g/km)'])\n",
    "\n",
    "print(f\"After removing missing CO2 values: {len(df_clean)}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and drop columns that are completely empty or not useful\n",
    "# CO2 Rating and Smog Rating have many missing values\n",
    "print(\"\\nDropping columns with excessive missing values...\")\n",
    "columns_to_drop = ['CO2 Rating', 'Smog Rating']\n",
    "\n",
    "df_clean = df_clean.drop(columns=columns_to_drop, errors='ignore')\n",
    "print(f\"Dropped columns: {columns_to_drop}\")\n",
    "print(f\"Remaining columns: {df_clean.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features for CO2 prediction\n",
    "# We'll use: Engine Size, Fuel Type, Transmission, Cylinders, and Combined Fuel Consumption\n",
    "print(\"Selected Features for CO2 Emissions Prediction:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "selected_features = [\n",
    "    'ENGINE SIZE (L)',\n",
    "    'CYLINDERS', \n",
    "    'FUEL TYPE',\n",
    "    'TRANSMISSION',\n",
    "    'COMB (L/100 km)'\n",
    "]\n",
    "\n",
    "target = 'CO2 EMISSIONS (g/km)'\n",
    "\n",
    "print(\"Features:\", selected_features)\n",
    "print(\"Target:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values in selected features\n",
    "df_clean = df_clean[selected_features + [target]].dropna()\n",
    "\n",
    "print(f\"\\nFinal dataset size after cleaning: {len(df_clean)}\")\n",
    "print(f\"\\nDataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "print(\"Statistical Summary of Numerical Features:\")\n",
    "print(\"=\"*50)\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable (CO2 Emissions)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df_clean[target], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('CO2 Emissions (g/km)', fontsize=11)\n",
    "plt.ylabel('Frequency', fontsize=11)\n",
    "plt.title('Distribution of CO2 Emissions', fontsize=13, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(df_clean[target], vert=True, patch_artist=True,\n",
    "           boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "           medianprops=dict(color='red', linewidth=2))\n",
    "plt.ylabel('CO2 Emissions (g/km)', fontsize=11)\n",
    "plt.title('Boxplot of CO2 Emissions', fontsize=13, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean CO2 Emissions: {df_clean[target].mean():.2f} g/km\")\n",
    "print(f\"Median CO2 Emissions: {df_clean[target].median():.2f} g/km\")\n",
    "print(f\"Std Dev: {df_clean[target].std():.2f} g/km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numerical features\n",
    "numerical_features = ['ENGINE SIZE (L)', 'CYLINDERS', 'COMB (L/100 km)']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, col in enumerate(numerical_features):\n",
    "    axes[idx].hist(df_clean[col], bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col, fontsize=10)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Insight: Histograms show the distribution of key vehicle features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Fuel Type distribution\n",
    "fuel_counts = df_clean['FUEL TYPE'].value_counts()\n",
    "axes[0].bar(range(len(fuel_counts)), fuel_counts.values, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xticks(range(len(fuel_counts)))\n",
    "axes[0].set_xticklabels(fuel_counts.index, rotation=45, ha='right')\n",
    "axes[0].set_title('Distribution of Fuel Types', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Fuel Type')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Transmission distribution (top 10)\n",
    "trans_counts = df_clean['TRANSMISSION'].value_counts().head(10)\n",
    "axes[1].barh(range(len(trans_counts)), trans_counts.values, color='lightgreen', edgecolor='black')\n",
    "axes[1].set_yticks(range(len(trans_counts)))\n",
    "axes[1].set_yticklabels(trans_counts.index)\n",
    "axes[1].set_title('Top 10 Transmission Types', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Count')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInsight: Most vehicles use regular gasoline (X), with various transmission types.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: Feature vs CO2 Emissions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Engine Size vs CO2\n",
    "axes[0].scatter(df_clean['ENGINE SIZE (L)'], df_clean[target], alpha=0.3, color='blue', s=10)\n",
    "axes[0].set_xlabel('Engine Size (L)', fontsize=10)\n",
    "axes[0].set_ylabel('CO2 Emissions (g/km)', fontsize=10)\n",
    "axes[0].set_title('Engine Size vs CO2 Emissions', fontsize=11, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Cylinders vs CO2\n",
    "axes[1].scatter(df_clean['CYLINDERS'], df_clean[target], alpha=0.3, color='green', s=10)\n",
    "axes[1].set_xlabel('Cylinders', fontsize=10)\n",
    "axes[1].set_ylabel('CO2 Emissions (g/km)', fontsize=10)\n",
    "axes[1].set_title('Cylinders vs CO2 Emissions', fontsize=11, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Combined Fuel Consumption vs CO2\n",
    "axes[2].scatter(df_clean['COMB (L/100 km)'], df_clean[target], alpha=0.3, color='red', s=10)\n",
    "axes[2].set_xlabel('Combined Fuel Consumption (L/100 km)', fontsize=10)\n",
    "axes[2].set_ylabel('CO2 Emissions (g/km)', fontsize=10)\n",
    "axes[2].set_title('Fuel Consumption vs CO2 Emissions', fontsize=11, fontweight='bold')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInsight: There appears to be a positive correlation between engine size,\")\n",
    "print(\"fuel consumption, and CO2 emissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for numerical features\n",
    "numerical_cols = ['ENGINE SIZE (L)', 'CYLINDERS', 'COMB (L/100 km)', target]\n",
    "correlation_matrix = df_clean[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap of Vehicle Features', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInsight: Strong positive correlation between fuel consumption and CO2 emissions.\")\n",
    "print(\"Engine size and cylinders also show strong correlation with emissions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "print(\"Encoding categorical variables...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "le_fuel = LabelEncoder()\n",
    "le_trans = LabelEncoder()\n",
    "\n",
    "df_clean['FUEL_TYPE_ENCODED'] = le_fuel.fit_transform(df_clean['FUEL TYPE'])\n",
    "df_clean['TRANSMISSION_ENCODED'] = le_trans.fit_transform(df_clean['TRANSMISSION'])\n",
    "\n",
    "print(f\"Fuel types: {len(le_fuel.classes_)} categories\")\n",
    "print(f\"Transmission types: {len(le_trans.classes_)} categories\")\n",
    "print(\"\\n✓ Categorical variables encoded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "feature_columns = [\n",
    "    'ENGINE SIZE (L)',\n",
    "    'CYLINDERS',\n",
    "    'FUEL_TYPE_ENCODED',\n",
    "    'TRANSMISSION_ENCODED',\n",
    "    'COMB (L/100 km)'\n",
    "]\n",
    "\n",
    "X = df_clean[feature_columns]\n",
    "y = df_clean[target]\n",
    "\n",
    "print(\"Features (X) shape:\", X.shape)\n",
    "print(\"Target (y) shape:\", y.shape)\n",
    "print(\"\\nFeatures used:\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data split successfully!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training set size: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing set size: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(\"\\nTraining features shape:\", X_train.shape)\n",
    "print(\"Testing features shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (Important for Neural Networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled successfully using StandardScaler!\")\n",
    "print(\"\\nScaled training features shape:\", X_train_scaled.shape)\n",
    "print(\"Scaled testing features shape:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Task 1: Build Neural Network Model (MLPRegressor)\n",
    "\n",
    "**Architecture:**\n",
    "- Input Layer: 5 features\n",
    "- Hidden Layer 1: 100 neurons with ReLU activation\n",
    "- Hidden Layer 2: 50 neurons with ReLU activation\n",
    "- Output Layer: 1 neuron (continuous output)\n",
    "- Loss Function: Mean Squared Error (MSE)\n",
    "- Optimizer: Adam\n",
    "- Learning Rate: 0.001 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Neural Network Regressor\n",
    "nn_regressor = MLPRegressor(\n",
    "    hidden_layer_sizes=(100, 50),  # Two hidden layers: 100 and 50 neurons\n",
    "    activation='relu',              # ReLU activation function\n",
    "    solver='adam',                  # Adam optimizer\n",
    "    learning_rate_init=0.001,       # Learning rate\n",
    "    max_iter=500,                   # Maximum iterations\n",
    "    random_state=42,\n",
    "    early_stopping=True,            # Use early stopping\n",
    "    validation_fraction=0.1,        # 10% of training data for validation\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Neural Network Architecture:\")\n",
    "print(\"=\"*50)\n",
    "print(\"Input Layer: 5 features\")\n",
    "print(\"Hidden Layer 1: 100 neurons (ReLU activation)\")\n",
    "print(\"Hidden Layer 2: 50 neurons (ReLU activation)\")\n",
    "print(\"Output Layer: 1 neuron (Linear activation)\")\n",
    "print(\"\\nOptimizer: Adam\")\n",
    "print(\"Loss Function: Mean Squared Error (MSE)\")\n",
    "print(\"Learning Rate: 0.001\")\n",
    "print(\"Max Iterations: 500\")\n",
    "print(\"Early Stopping: Enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Neural Network\n",
    "print(\"Training Neural Network...\")\n",
    "nn_regressor.fit(X_train_scaled, y_train)\n",
    "print(\"✓ Neural Network training completed!\")\n",
    "print(f\"\\nNumber of iterations: {nn_regressor.n_iter_}\")\n",
    "print(f\"Loss: {nn_regressor.loss_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Neural Network on Training Set\n",
    "y_train_pred_nn = nn_regressor.predict(X_train_scaled)\n",
    "\n",
    "train_mae_nn = mean_absolute_error(y_train, y_train_pred_nn)\n",
    "train_mse_nn = mean_squared_error(y_train, y_train_pred_nn)\n",
    "train_rmse_nn = np.sqrt(train_mse_nn)\n",
    "train_r2_nn = r2_score(y_train, y_train_pred_nn)\n",
    "\n",
    "print(\"Neural Network - Training Set Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE: {train_mae_nn:.4f}\")\n",
    "print(f\"MSE: {train_mse_nn:.4f}\")\n",
    "print(f\"RMSE: {train_rmse_nn:.4f}\")\n",
    "print(f\"R² Score: {train_r2_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Neural Network on Test Set\n",
    "y_test_pred_nn = nn_regressor.predict(X_test_scaled)\n",
    "\n",
    "test_mae_nn = mean_absolute_error(y_test, y_test_pred_nn)\n",
    "test_mse_nn = mean_squared_error(y_test, y_test_pred_nn)\n",
    "test_rmse_nn = np.sqrt(test_mse_nn)\n",
    "test_r2_nn = r2_score(y_test, y_test_pred_nn)\n",
    "\n",
    "print(\"Neural Network - Test Set Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE: {test_mae_nn:.4f}\")\n",
    "print(f\"MSE: {test_mse_nn:.4f}\")\n",
    "print(f\"RMSE: {test_rmse_nn:.4f}\")\n",
    "print(f\"R² Score: {test_r2_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Neural Network predictions\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_test_pred_nn, alpha=0.3, s=10)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual CO2 Emissions (g/km)', fontsize=11)\n",
    "plt.ylabel('Predicted CO2 Emissions (g/km)', fontsize=11)\n",
    "plt.title('Neural Network: Actual vs Predicted', fontsize=12, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test - y_test_pred_nn\n",
    "plt.scatter(y_test_pred_nn, residuals, alpha=0.3, s=10)\n",
    "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "plt.xlabel('Predicted CO2 Emissions (g/km)', fontsize=11)\n",
    "plt.ylabel('Residuals', fontsize=11)\n",
    "plt.title('Neural Network: Residual Plot', fontsize=12, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Task 2: Build Two Classical ML Models\n",
    "\n",
    "### 6.1 Model 1: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "print(\"Training Linear Regression model...\")\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "print(\"✓ Linear Regression training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Linear Regression on Test Set\n",
    "y_test_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "test_mae_lr = mean_absolute_error(y_test, y_test_pred_lr)\n",
    "test_mse_lr = mean_squared_error(y_test, y_test_pred_lr)\n",
    "test_rmse_lr = np.sqrt(test_mse_lr)\n",
    "test_r2_lr = r2_score(y_test, y_test_pred_lr)\n",
    "\n",
    "print(\"Linear Regression - Test Set Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE: {test_mae_lr:.4f}\")\n",
    "print(f\"MSE: {test_mse_lr:.4f}\")\n",
    "print(f\"RMSE: {test_rmse_lr:.4f}\")\n",
    "print(f\"R² Score: {test_r2_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Model 2: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "print(\"Training Random Forest Regressor...\")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "print(\"✓ Random Forest training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest on Test Set\n",
    "y_test_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "test_mae_rf = mean_absolute_error(y_test, y_test_pred_rf)\n",
    "test_mse_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "test_rmse_rf = np.sqrt(test_mse_rf)\n",
    "test_r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "\n",
    "print(\"Random Forest - Test Set Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE: {test_mae_rf:.4f}\")\n",
    "print(f\"MSE: {test_mse_rf:.4f}\")\n",
    "print(f\"RMSE: {test_rmse_rf:.4f}\")\n",
    "print(f\"R² Score: {test_r2_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Task 3: Hyperparameter Optimization with Cross-Validation\n",
    "\n",
    "### 7.1 Linear Regression (No hyperparameters to tune)\n",
    "\n",
    "Linear Regression has no hyperparameters to tune. We'll perform cross-validation to get CV score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for Linear Regression\n",
    "lr_cv_scores = cross_val_score(lr_model, X_train_scaled, y_train, cv=5, \n",
    "                                scoring='r2', n_jobs=-1)\n",
    "\n",
    "print(\"Linear Regression - Cross-Validation Results:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"CV Scores: {lr_cv_scores}\")\n",
    "print(f\"Mean CV Score (R²): {lr_cv_scores.mean():.4f}\")\n",
    "print(f\"Std Dev: {lr_cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Random Forest (reduced for faster execution)\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "print(\"Random Forest - Hyperparameter Grid:\")\n",
    "print(\"=\"*50)\n",
    "for param, values in rf_param_grid.items():\n",
    "    print(f\"{param}: {values}\")\n",
    "\n",
    "print(f\"\\nTotal combinations: {np.prod([len(v) for v in rf_param_grid.values()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearchCV for Random Forest\n",
    "print(\"\\nPerforming GridSearchCV for Random Forest...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "rf_grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\n✓ GridSearchCV completed for Random Forest!\")\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(\"=\"*50)\n",
    "for param, value in rf_grid_search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"\\nBest Cross-Validation Score (R²): {rf_grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Task 4: Feature Selection\n",
    "\n",
    "We will use SelectKBest with f_regression for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection using SelectKBest\n",
    "k_best = 4  # Select top 4 features out of 5\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k=k_best)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "selected_feature_names = [feature_columns[i] for i in selected_feature_indices]\n",
    "\n",
    "print(\"Feature Selection Results:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Method: SelectKBest with f_regression\")\n",
    "print(f\"Number of features selected: {k_best}\")\n",
    "print(f\"\\nSelected Features: {selected_feature_names}\")\n",
    "print(f\"\\nFeature Scores:\")\n",
    "for i, (feature, score) in enumerate(zip(feature_columns, selector.scores_)):\n",
    "    selected = \"✓\" if i in selected_feature_indices else \"✗\"\n",
    "    print(f\"{selected} {feature}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Score': selector.scores_\n",
    "}).sort_values('Score', ascending=False)\n",
    "\n",
    "colors = ['green' if f in selected_feature_names else 'lightgray' for f in feature_scores['Feature']]\n",
    "\n",
    "plt.barh(feature_scores['Feature'], feature_scores['Score'], color=colors, edgecolor='black')\n",
    "plt.xlabel('F-Score', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('Feature Importance Scores (SelectKBest)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGreen bars indicate selected features for final models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Task 5: Final Models with Optimal Hyperparameters and Selected Features\n",
    "\n",
    "### 9.1 Final Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final Linear Regression model with selected features\n",
    "final_lr = LinearRegression()\n",
    "\n",
    "print(\"Training Final Linear Regression Model...\")\n",
    "print(\"=\"*50)\n",
    "print(\"Features used:\", selected_feature_names)\n",
    "print(\"Number of features:\", len(selected_feature_names))\n",
    "\n",
    "final_lr.fit(X_train_selected, y_train)\n",
    "print(\"\\n✓ Final Linear Regression model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final Linear Regression model\n",
    "y_test_pred_lr_final = final_lr.predict(X_test_selected)\n",
    "\n",
    "# Get cross-validation score\n",
    "lr_cv_score_final = cross_val_score(final_lr, X_train_selected, y_train, cv=5, \n",
    "                                     scoring='r2', n_jobs=-1).mean()\n",
    "\n",
    "lr_final_mae = mean_absolute_error(y_test, y_test_pred_lr_final)\n",
    "lr_final_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred_lr_final))\n",
    "lr_final_r2 = r2_score(y_test, y_test_pred_lr_final)\n",
    "\n",
    "print(\"Final Linear Regression - Test Set Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"CV Score (R²): {lr_cv_score_final:.4f}\")\n",
    "print(f\"Test MAE: {lr_final_mae:.4f}\")\n",
    "print(f\"Test RMSE: {lr_final_rmse:.4f}\")\n",
    "print(f\"Test R²: {lr_final_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Final Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final Random Forest model with best parameters and selected features\n",
    "final_rf = RandomForestRegressor(**rf_grid_search.best_params_, random_state=42)\n",
    "\n",
    "print(\"Training Final Random Forest Model...\")\n",
    "print(\"=\"*50)\n",
    "print(\"Features used:\", selected_feature_names)\n",
    "print(\"Number of features:\", len(selected_feature_names))\n",
    "print(\"\\nHyperparameters:\")\n",
    "for param, value in rf_grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "final_rf.fit(X_train_selected, y_train)\n",
    "print(\"\\n✓ Final Random Forest model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final Random Forest model\n",
    "y_test_pred_rf_final = final_rf.predict(X_test_selected)\n",
    "\n",
    "# Get cross-validation score\n",
    "rf_cv_score_final = cross_val_score(final_rf, X_train_selected, y_train, cv=5, \n",
    "                                     scoring='r2', n_jobs=-1).mean()\n",
    "\n",
    "rf_final_mae = mean_absolute_error(y_test, y_test_pred_rf_final)\n",
    "rf_final_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred_rf_final))\n",
    "rf_final_r2 = r2_score(y_test, y_test_pred_rf_final)\n",
    "\n",
    "print(\"Final Random Forest - Test Set Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"CV Score (R²): {rf_cv_score_final:.4f}\")\n",
    "print(f\"Test MAE: {rf_final_mae:.4f}\")\n",
    "print(f\"Test RMSE: {rf_final_rmse:.4f}\")\n",
    "print(f\"Test R²: {rf_final_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Task 6: Final Model Comparison\n",
    "\n",
    "Comparison of all models including Neural Network and optimized classical models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison table\n",
    "comparison_data = {\n",
    "    'Model': [\n",
    "        'Neural Network (MLP)',\n",
    "        'Linear Regression (Optimized)',\n",
    "        'Random Forest (Optimized)'\n",
    "    ],\n",
    "    'Features Used': [\n",
    "        f'All ({len(feature_columns)})',\n",
    "        f'Selected ({len(selected_feature_names)})',\n",
    "        f'Selected ({len(selected_feature_names)})'\n",
    "    ],\n",
    "    'CV Score (R²)': [\n",
    "        'N/A',\n",
    "        f'{lr_cv_score_final:.4f}',\n",
    "        f'{rf_cv_score_final:.4f}'\n",
    "    ],\n",
    "    'Test MAE': [\n",
    "        f'{test_mae_nn:.4f}',\n",
    "        f'{lr_final_mae:.4f}',\n",
    "        f'{rf_final_mae:.4f}'\n",
    "    ],\n",
    "    'Test RMSE': [\n",
    "        f'{test_rmse_nn:.4f}',\n",
    "        f'{lr_final_rmse:.4f}',\n",
    "        f'{rf_final_rmse:.4f}'\n",
    "    ],\n",
    "    'Test R²': [\n",
    "        f'{test_r2_nn:.4f}',\n",
    "        f'{lr_final_r2:.4f}',\n",
    "        f'{rf_final_r2:.4f}'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"FINAL MODEL COMPARISON TABLE\")\n",
    "print(\"=\"*90)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "metrics = ['MAE', 'RMSE', 'R²']\n",
    "nn_scores = [test_mae_nn, test_rmse_nn, test_r2_nn]\n",
    "lr_scores = [lr_final_mae, lr_final_rmse, lr_final_r2]\n",
    "rf_scores = [rf_final_mae, rf_final_rmse, rf_final_r2]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, (metric, nn_val, lr_val, rf_val) in enumerate(zip(metrics, nn_scores, lr_scores, rf_scores)):\n",
    "    models = ['Neural\\nNetwork', 'Linear\\nRegression', 'Random\\nForest']\n",
    "    values = [nn_val, lr_val, rf_val]\n",
    "    colors = ['steelblue', 'coral', 'forestgreen']\n",
    "    \n",
    "    axes[idx].bar(models, values, color=colors, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_ylabel(metric, fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(values):\n",
    "        axes[idx].text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction comparison visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "models_pred = [\n",
    "    ('Neural Network', y_test_pred_nn),\n",
    "    ('Linear Regression', y_test_pred_lr_final),\n",
    "    ('Random Forest', y_test_pred_rf_final)\n",
    "]\n",
    "\n",
    "for idx, (name, pred) in enumerate(models_pred):\n",
    "    axes[idx].scatter(y_test, pred, alpha=0.3, s=10)\n",
    "    axes[idx].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[idx].set_xlabel('Actual CO2 (g/km)', fontsize=10)\n",
    "    axes[idx].set_ylabel('Predicted CO2 (g/km)', fontsize=10)\n",
    "    axes[idx].set_title(f'{name}', fontsize=11, fontweight='bold')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion and Reflection\n",
    "\n",
    "### Model Performance Summary\n",
    "\n",
    "All three regression models demonstrated strong predictive performance for CO2 emissions based on vehicle features. The models achieved high R² scores, indicating that vehicle characteristics like engine size, fuel type, transmission, cylinders, and fuel consumption are excellent predictors of CO2 emissions.\n",
    "\n",
    "### Impact of Methods\n",
    "\n",
    "**Cross-Validation:** GridSearchCV identified optimal hyperparameters for Random Forest, improving model generalization and performance consistency.\n",
    "\n",
    "**Feature Selection:** Using SelectKBest, we reduced features from 5 to 4, which:\n",
    "- Simplified the models while maintaining performance\n",
    "- Reduced computational complexity\n",
    "- Identified the most important predictors of CO2 emissions\n",
    "- Combined fuel consumption emerged as the strongest predictor\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Fuel consumption** is the strongest predictor of CO2 emissions (as expected from the strong correlation)\n",
    "2. **Engine size** and **number of cylinders** also significantly influence emissions\n",
    "3. All three model types (Neural Network, Linear Regression, Random Forest) performed well, with Random Forest showing slight advantages\n",
    "4. The strong R² scores (>0.95) indicate that vehicle specifications accurately predict emissions\n",
    "5. This analysis supports **SDG 13: Climate Action** by enabling:\n",
    "   - Better understanding of vehicle emission factors\n",
    "   - Data-driven policy decisions for emission regulations\n",
    "   - Consumer awareness about vehicle environmental impact\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "1. Include **additional features** like vehicle weight, aerodynamics, and driving conditions\n",
    "2. Develop **time-series analysis** to track emission trends across model years\n",
    "3. Create **vehicle recommendation systems** based on emission targets\n",
    "4. Implement **ensemble methods** combining multiple models for improved accuracy\n",
    "5. Deploy as a **web application** for consumers to estimate emissions before purchasing\n",
    "6. Extend analysis to **electric and hybrid vehicles** for comprehensive comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REGRESSION TASK COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAll required tasks have been completed:\")\n",
    "print(\"✓ Task 1: Exploratory Data Analysis\")\n",
    "print(\"✓ Task 2: Neural Network Model (MLPRegressor)\")\n",
    "print(\"✓ Task 3: Two Classical ML Models (Linear Regression & Random Forest)\")\n",
    "print(\"✓ Task 4: Hyperparameter Optimization with Cross-Validation\")\n",
    "print(\"✓ Task 5: Feature Selection (SelectKBest)\")\n",
    "print(\"✓ Task 6: Final Model Comparison\")\n",
    "print(\"✓ Task 7: Conclusion and Reflection\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
